Sentence	Question	Source	Text
S1	Q1	Human	A linguistic corpus often contains a broad set of linguistic information on a variety of topics, while datasets in other fields are specific to certain instances and can be quantitative rather than linguistic. 
S2	Q1	Human	A linguistic corpus is compiled texts or speech that serve to answer questions about linguistic phenomena.
S3	Q1	Human	A linguistic corpus is generally constituted of a collection of curated linguistic data from a variety of written and (sometimes) spoken language sources for a multitude of purposes; which is contrary to the datasets of other fields in that they are generally constituted of numerical or semantic data for a specific or limited purpose.
S4	Q1	AI	A linguistic corpus is a collection of language data that is specifically designed for linguistic analysis, whereas a dataset in other fields may refer to any structured collection of data used for analysis or machine learning purposes.
S5	Q1	AI	A linguistic corpus is a collection of authentic language data designed for linguistic analysis, while a dataset in other fields refers to a structured collection of data used for various analytical or machine learning purposes.
S6	Q1	AI	A linguistic corpus is a collection of texts used for linguistic analysis, while a dataset in other fields is a collection of data used for statistical analysis or machine learning.
S7	Q2	Human	I was very interested in the Brown Corpus because although it was initially a very cutting-edge corpus, I thought it was fascinating that the data it contained is not adequate for many research questions in linguistics today, showing the growth of the field. 
S8	Q2	Human	The megacorpora stood out to me because of their sheer impressiveness; of these COCA stood out to me due to its claim at being the most "representative" corpus of English.
S9	Q2	Human	Switchboard Dialog Act Corpus because it seems to be entirely spoken data of telephone conversations as opposed to being mainly text. This could also allow for more natural use of the language than in text. 
S10	Q2	AI	The British National Corpus (BNC) is an important and widely used corpus in linguistics because of its size, diversity of text types, and balanced representation of spoken and written language.
S11	Q2	AI	Among the corpora mentioned in Chapter 2, the British National Corpus stood out due to its large and diverse collection of written and spoken texts from the late 20th century, making it a valuable resource for studying contemporary English language usage.
S12	Q2	AI	The Brown Corpus is considered a groundbreaking corpus in computational linguistics due to its representativeness and availability.
S13	Q3	Human	I think that the Brown Corpus was initially created with the lofty goal of serving as a definitive collection of texts and linguistic information that could be used for research, and although it has not maintained its position as a definitive source, it is still useful for linguistic research even in the modern era. 
S14	Q3	Human	As I implied, COCA was created to be the most "representative" corpus of English and thus purposefully includes specific proportions of different kinds of media to maximize its representativeness of all English that is produced.
S15	Q3	Human	Allows for more natural use of the language in a spoken context than simply having people write out their conversations or obtaining data from their written texts. 
S16	Q3	AI	The creation of the Brown Corpus was motivated by the need for a representative sample of American English language usage for linguistic research and computational analysis.
S17	Q3	AI	The creation of the corpus may have been motivated by a desire to provide a reliable and up-to-date representation of the English language as it is used in various contexts in Britain.
S18	Q3	AI	The creation of the corpus may have been motivated by a desire to document the diversity and evolution of British English language usage across different registers, genres, and social groups for various linguistic and practical purposes.
S19	Q4	Human	Even in the same language, there can be a variety of different dialects and ways of using the language, and when creating a corpus there is a lot of discretion used when choosing sources, meaning that there are a nearly infinite number of different source combinations that corpora can utilize which leads to differences. 
S20	Q4	Human	Every linguist thinks that the materials that *they* compile and the ways *they* annotate it are relevant to a linguistic question they want to answer; not all corpora can answer the same question in the same ways. To be specific, different corpora will include different information about the speaker/writer, the (morpho)syntactic properties of the writing/speech, etc. and this information will be used to answer different linguistic questions.
S21	Q4	Human	There are many different corpora even in the same language because, over time, there has been many changes to language which are worth studying and comparing. 
S22	Q4	Human	There are a number of idiosyncrasies that exist even between dialects of the same language which some may feel is necessary to record in isolation (the meaning of the word "biscuit", for instance, is different between American and British English).
S23	Q4	AI	There are many different corpora even for the same language like BE or SAE because each corpus serves a specific purpose, such as representing a particular region, time period, genre, or social group, and different corpora may have different characteristics, sampling methods, and annotations that are relevant to different linguistic research questions and practical applications.
S24	Q4	AI	There are so many different corpora, even for the same language like BE or SAE, because each corpus is designed for a specific research or practical purpose and reflects different sampling criteria, data collection methods, annotation schemes, and data formats, among other factors.
S25	Q4	AI	There are many different corpora for the same language like BE or SAE because different corpora may focus on different genres, time periods, geographical regions, or social groups, and serve different research or practical needs in linguistics, education, or language technologies.
S26	Q4	AI	There are many different corpora, even for the same language like BE or SAE, because they may focus on different genres, time periods, regional variations, social groups, or research questions, and may have different design features and sampling criteria.
S27	Q5	Human	It is difficult to obtain legal samples of spontaneously spoken language, and transcription and annotation of this speech can be difficult and expensive.  
S28	Q5	Human	If speakers are aware of their speech being recorded, then it becomes less spontaneous and therefore less representative of how people actually talk; getting consent to record spontaneous speech is thus ethically difficult.
S29	Q5	Human	Transcribing the spoken conversations for spontaneous corpora can be a hassle or too extensive of a task to do accurately.
S30	Q5	Human	Spoken language information is generally more difficult to curate for a corpus, as it includes linguistic information (such as clitics) that may be challenging to tokenize; in addition to this, much of the recorded spoken language available for such a task is merely recited from a written work (newscast, written speeches, etc.).
S31	Q5	AI	Corpora of spontaneous spoken language are relatively rare because they are difficult and expensive to collect and transcribe, require ethical considerations and consent from participants, and may contain non-standard or sensitive language that requires careful handling.
S32	Q5	AI	Corpora of spontaneous spoken language are relatively rare because they are challenging and expensive to collect, transcribe, and annotate due to their unscripted, variable, and context-dependent nature, and may raise ethical and privacy concerns.
S33	Q5	AI	Corpora of spontaneous spoken language are relatively rare because they require extensive time and effort to collect, transcribe, and annotate, and may involve ethical and privacy concerns, as well as challenges related to speaker variability and naturalness.
S34	Q5	AI	Corpora of spontaneous spoken language are relatively rare because they are more challenging and expensive to collect, transcribe, and annotate compared to written language, and may require ethical considerations and consent from participants.
S35	Q6	Human	The Switchboard Corpus contains samples from spontaneous conversations over the phone, which is useful because it shows how speech is used in everyday life rather than in writing or formal presentations such as newscasts. 
S36	Q6	Human	British Academic Spoken English (BASE)
S37	Q6	AI	The Santa Barbara Corpus of Spoken American English is a decent corpus of spoken English as it contains transcriptions and audio recordings of spontaneous conversations from a diverse group of speakers across the United States, providing a representative sample of American English in different social and regional contexts.
S38	Q6	AI	The Corpus of Contemporary American English (COCA) is a good corpus of spoken English because it contains a large and balanced collection of naturally occurring speech from a variety of genres and regions, and allows for easy and customizable searches and analysis.
S39	Q7	Human	The sources were intended to be representative of many forms of English in order to provide coverage of as many different styles of text as possible, leading to the inclusion of a variety of different genres. 
S40	Q7	Human	A mix of sources allows for a broader understanding of the language used, as opposed to concentrating on only one type of composition (such as Science Fiction texts) where the language used is specific to that category. 
S41	Q7	AI	The mix of sources in the Brown Corpus, which includes written texts from various genres and registers, was motivated by a desire to provide a representative sample of American English usage from the mid-20th century for linguistic research and language teaching.
S42	Q7	AI	The mix of sources in the Brown Corpus was motivated by a desire to capture a representative sample of American English usage across various written genres and time periods, while also ensuring a balance between different types of texts and a manageable size for computational analysis.
S43	Q8	Human	I think that this was a good choice because to the native Engish speaker ear, there can often be a level of ambiguity about how a dropped g sounds (at least in my experiences), making it difficult to distinguish between "going" and "goin" at times, so this choice leads to less bias in the way that conversations are transcribed. 
S44	Q8	Human	I think this was a fine choice; English speakers at least somewhat conceptualize "we're" as one unit due to its orthographic representation as one word, but we do not think at all about g-drop since, compared to "we're", there is no orthographic alternation.
S45	Q8	Human	Do not think it was a good choice because it does not accurately represent the spontaneous speech of American English used by the speakers. 
S46	Q8	Human	Though perhaps it was a necessary omission on the part of the developers of the corpus for one reason or another, it seems to me a limitation, as the data does not, in this case, accurately represent the particulars of spoken language.
S47	Q8	AI	The choice to not represent g-drop in the Switchboard Corpus may have been influenced by the researchers' focus on capturing more formal and standard features of spoken language, but it may also limit the corpus's representativeness of certain dialects and styles of speech.
S48	Q8	AI	It's difficult to determine whether it was a good choice or not, as it likely depends on the specific research goals and linguistic phenomena being studied.
S49	Q8	AI	It depends on the specific research goals and the intended use of the Switchboard Corpus, but omitting g-drop phenomena could limit its applicability in certain areas of linguistic research.
S50	Q8	AI	It was likely a deliberate choice to prioritize annotating more salient linguistic phenomena in the Switchboard Corpus, but the exclusion of g-drop may limit its usefulness for studying certain aspects of informal spoken language.
S51	Q9	Human	I believe that I would want to choose a corpus that focuses on spoken data rather than Project Gutenberg because "gonna" is used nearly exclusively in speech and rarely in written texts (with the exception of some dialogue). 
S52	Q9	Human	No it would not be; gonna is a mainly spoken phenomenon and Project Gutenberg is a repository of written materials so it would be better to consult a spoken language corpus unless you are specifically researching the transition of gonna into written English.
S53	Q9	Human	Project Gutenberg might not be the best resource because it lacks contemporary texts due to copyright reasons and 'gonna' is a term that has been in usage, for the most part, in recent times. 
S54	Q9	Human	Because most of the information featured on the Gutenberg Project is in the public domain and are largely literary works, it would probably not be a good basis for such analyses, as the language used in pre-1923 literature is unlikely to contain the word "gonna", which has a more contemporary usage.
S55	Q9	AI	Project Gutenberg may not be a suitable basis for analyzing the usage of gonna, as it primarily contains written texts that may not accurately reflect the frequency and usage patterns of this colloquialism in spoken language.
S56	Q9	AI	No, Project Gutenberg is unlikely to be a good basis for analyzing the usage of gonna since it primarily contains written texts rather than spoken language, which is where gonna is more commonly used.
S57	Q9	AI	No, Project Gutenberg would not be a good basis for analyzing the usage of gonna as it primarily contains written texts, whereas gonna is a feature of informal spoken language.
S58	Q9	AI	Project Gutenberg may not be the best basis for analyzing the usage of gonna as it primarily contains written texts and gonna is a more commonly used in informal spoken language.
S59	Q10	Human	There seem to be a decent number of code swtiching articles and corpora, but most seem to be limited to American bilingual speakers, and there appears to be a geographic separation of corpora and studies since bilingual speakers in the Southwestern US tend to have a different use of language than speakers in areas like Miami. 
S60	Q10	Human	Many of the papers on the subject are not publicly available for viewing; also there is a greater than average concentration of spoken data.
S61	Q10	AI	When searching for papers and corpora on code switching of bilingual English-Spanish speakers, it becomes apparent that there is a significant amount of research and resources available, indicating a growing interest in the study of bilingual language use.
S62	Q10	AI	When searching for papers and corpora on code switching of bilingual English-Spanish speakers, I notice that there is a relatively large amount of research and resources available on this topic, likely due to the prevalence of bilingualism in many English-Spanish speaking communities.
S63	Q11	Human	It would be difficult to obtain spoken samples of this code switching because speaker bases for these languages are relatively small and obtaining legal rights to conversations in such a small group would pose a challenge. Additionally, code switching must be spontaneous, so producing the desired result would be hard. 
S64	Q11	Human	One challenge is finding enough data to warrant building a corpus since finding bilingual individuals of the two languages may be difficult to amass. 
S65	Q11	Human	There may be a limited number of linguistic resources that include the simultaneous use of both Flemish and Wallonian; and therefore it may be necessary to either generate one's own resources (such as bilingual interviews) or go to great lengths in procuring linguistic information from what limited resources are available. There may also be some difficulties presented in the actual construction of the corpus, as the annotation and categorization of the linguistic tokens may be a challenging process given any phonetic and/or orthographic similarities between the languages.
S66	Q11	AI	Some challenges that could be faced in compiling a corpus of code switching between bilingual speakers of Flemish and Wallonian include finding a representative and diverse set of speakers, ensuring that the conversations captured are natural and spontaneous, and navigating potential ethical considerations in collecting and sharing sensitive linguistic data.
S67	Q11	AI	Some challenges in compiling a corpus of code switching between bilingual speakers of Flemish and Wallonian could include finding and recruiting a sufficient number of participants who are comfortable and proficient in both languages, ensuring that the corpus includes a diverse range of social situations and contexts, and addressing any ethical considerations related to participant privacy and consent.
S68	Q11	AI	Some challenges that could be faced in compiling a corpus of code switching between bilingual speakers of Flemish and Wallonian include finding a sufficient number of willing and representative participants, navigating potential political and cultural sensitivities surrounding the use of both languages, and developing a standardized methodology for data collection and annotation.